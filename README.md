# PrevisÃ£o de TendÃªncia do IBOVESPA com Machine Learning

Projeto desenvolvido como desafio da PÃ³s-GraduaÃ§Ã£o em Data Analytics (FIAP), focado em construir um modelo preditivo para a tendÃªncia diÃ¡ria do Ã­ndice IBOVESPA, com o objetivo de superar 75% de acurÃ¡cia.

**Resultado Chave: AcurÃ¡cia de 76,67% alcanÃ§ada com um modelo Random Forest.**

---

## 1. O Desafio

O objetivo era desenvolver um modelo de classificaÃ§Ã£o binÃ¡ria capaz de prever se o Ã­ndice IBOVESPA fecharia em alta (1) ou baixa (0) no dia seguinte.

**Requisitos:**
* Utilizar dados histÃ³ricos diÃ¡rios do IBOVESPA (mÃ­nimo de 2 anos).
* O conjunto de teste deveria ser composto pelos Ãºltimos 30 dias de dados disponÃ­veis.
* A acurÃ¡cia mÃ­nima do modelo no conjunto de teste deveria ser de **75%**.

---

## 2. Metodologia

O sucesso do projeto foi alcanÃ§ado atravÃ©s de uma estratÃ©gia de **filtragem de ruÃ­do** e **engenharia de atributos** robusta, transformando um problema de sÃ©rie temporal notoriamente volÃ¡til em um problema de classificaÃ§Ã£o supervisionada com sinal claro.

### 2.1. Limpeza e PrÃ©-Processamento

* **Fonte de Dados:** Dados histÃ³ricos diÃ¡rios do `investing.com`.
* **Limpeza:** Os dados foram tratados para converter colunas de texto em formatos numÃ©ricos, com atenÃ§Ã£o especial Ã  coluna `Vol.` (Volume), que exigiu o *parsing* de sufixos 'M' (MilhÃ£o) e 'K' (Mil).
* **OrdenaÃ§Ã£o:** Os dados foram ordenados cronologicamente para garantir a integridade da sÃ©rie temporal.

### 2.2. A EstratÃ©gia Vencedora: Filtro de RuÃ­do

Uma anÃ¡lise inicial revelou que tentar prever *qualquer* movimento diÃ¡rio (ex: +0.01%) resultava em modelos com performance medÃ­ocre (~50-60%), pois o "ruÃ­do" aleatÃ³rio do mercado era mais forte que o "sinal" preditivo.

A estratÃ©gia decisiva foi **redefinir o problema**:
1.  Foi estabelecido um **limite (threshold) de 0.5%**.
2.  O `target` foi definido como `1` (Alta) apenas para dias com retorno futuro `> +0.5%` e `0` (Baixa) para dias com retorno futuro `< -0.5%`.
3.  **Todos os dias com movimentos laterais (entre -0.5% e +0.5%) foram removidos do dataset.**

Essa abordagem de filtragem de ruÃ­do foi o fator chave para o sucesso, permitindo ao modelo focar apenas em movimentos significativos.

### 2.3. Engenharia de Atributos (Feature Engineering)

Para dar ao modelo um contexto histÃ³rico e de momentum, as seguintes features foram criadas para cada dia:

* **TendÃªncia (Janelas Deslizantes):**
    * `SMA_5`, `SMA_10`, `SMA_20`: MÃ©dias MÃ³veis Simples de curto e mÃ©dio prazo.
    * `SMA_Diff`: Diferencial entre as mÃ©dias de 12 e 26 dias (base do MACD).
* **Momentum (Janelas Deslizantes):**
    * `RSI_14`: Ãndice de ForÃ§a Relativa de 14 dias, para identificar sobrecompra/sobrevenda.
    * `Dist_SMA_20`: DistÃ¢ncia percentual do preÃ§o atual atÃ© sua mÃ©dia de 20 dias (mede o quÃ£o "esticado" o preÃ§o estÃ¡).
* **MemÃ³ria (Features Lagged):**
    * `Lag_1`, `Lag_2`, `Lag_3`: Retornos percentuais dos Ãºltimos 3 dias.
* **Risco e ConvicÃ§Ã£o:**
    * `Volatility_10`: Desvio padrÃ£o dos retornos dos Ãºltimos 10 dias.
    * `Vol.`: Volume de negociaÃ§Ã£o do dia (feature de confirmaÃ§Ã£o).

---

## 3. Modelagem e Resultados

Foram comparados trÃªs modelos distintos. A validaÃ§Ã£o foi feita em um conjunto de teste fixo, composto pelos Ãºltimos 30 pontos de dados "significativos" do nosso dataset filtrado.

### 3.1. ComparaÃ§Ã£o de AcurÃ¡cia

| Modelo | AcurÃ¡cia no Teste |
| :--- | :--- |
| **Random Forest** | **76.67%** ðŸ† |
| RegressÃ£o LogÃ­stica | 73.33% |
| XGBoost | 70.00% |

O `Random Forest` foi o vencedor, demonstrando a melhor capacidade de capturar os padrÃµes nÃ£o-lineares complexos das features criadas.

### 3.2. AnÃ¡lise de Confiabilidade do Modelo (Random Forest)

Atingir 76,67% de acurÃ¡cia foi a meta, mas a anÃ¡lise de confiabilidade prova o valor do modelo.

**Matriz de ConfusÃ£o (30 dias de teste):**

| Real \ Previsto | Baixa (0) | Alta (1) |
| :--- | :---: | :---: |
| **Baixa (0)** | 11 (VN) | 6 (FP) |
| **Alta (1)** | 1 (FN) | 12 (VP) |

**MÃ©tricas Chave:**

* **AcurÃ¡cia (Geral): 76.67%** (23 acertos em 30).
* **PrecisÃ£o (Alta): 67%** (Quando o modelo prevÃª "Alta", ele acerta 67% das vezes).
* **Recall (Alta): 92%** (O modelo conseguiu capturar 12 das 13 oportunidades reais de alta).
* **PrecisÃ£o (Baixa): 92%** (Quando o modelo prevÃª "Baixa", ele acerta 92% das vezes).
* **Recall (Baixa): 65%** (O modelo identificou 11 das 17 baixas reais).

O modelo demonstrou um perfil estratÃ©gico excelente: Ã© **extremamente confiÃ¡vel ao prever uma baixa** (evitando perdas) e **extremamente sensÃ­vel ao capturar oportunidades de alta** (maximizando ganhos).

### 3.3. ImportÃ¢ncia das Features

As features de *momentum* e o retorno do dia atual mostraram-se os preditores mais importantes para o modelo.

1.  `Return` (Retorno do dia)
2.  `Dist_SMA_20` (DistÃ¢ncia da MÃ©dia de 20 dias)
3.  `RSI_14` (Ãndice de ForÃ§a Relativa)

---

## 4. Tecnologias Utilizadas

* **Python 3**
* **Pandas:** Para manipulaÃ§Ã£o e limpeza dos dados.
* **Numpy:** Para cÃ¡lculos numÃ©ricos.
* **Scikit-learn (sklearn):** Para prÃ©-processamento (`StandardScaler`), modelagem (`RandomForestClassifier`, `LogisticRegression`) e avaliaÃ§Ã£o (`accuracy_score`, `classification_report`, `GridSearchCV`).
* **XGBoost:** Para modelagem (`XGBClassifier`).
* **Matplotlib & Seaborn:** Para visualizaÃ§Ã£o de dados.
* **Google Colab / Jupyter Notebook:** Como ambiente de desenvolvimento.

---

## 5. Como Executar

1.  Certifique-se de ter todas as bibliotecas acima instaladas (`pip install pandas numpy scikit-learn xgboost matplotlib seaborn`).
2.  FaÃ§a o download do arquivo `Dados_HistÃ³ricos_Ibovespa.csv` e do notebook `.ipynb`.
3.  Coloque ambos no mesmo diretÃ³rio.
4.  Abra e execute o notebook em um ambiente Jupyter.
